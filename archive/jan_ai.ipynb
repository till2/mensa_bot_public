{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9daa33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import json\n",
    "\n",
    "# Setup the connection to your local server\n",
    "conn = http.client.HTTPConnection(\"127.0.0.1\", 1337)\n",
    "headers = {'Content-Type': \"application/json\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99d6ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '''\n",
    "\n",
    "1\n",
    "Representation Learning: A Review and New\n",
    "Perspectives\n",
    "Yoshua Bengio†, Aaron Courville, and Pascal Vincent†\n",
    "Department of computer science and operations research, U. Montreal\n",
    "† also, Canadian Institute for Advanced Research (CIFAR)\n",
    "F\n",
    "Abstract—\n",
    "The success of machine learning algorithms generally depends on\n",
    "data representation, and we hypothesize that this is because different\n",
    "representations can entangle and hide more or less the different ex-\n",
    "planatory factors of variation behind the data. Although specific domain\n",
    "knowledge can be used to help design representations, learning with\n",
    "generic priors can also be used, and the quest for AI is motivating\n",
    "the design of more powerful representation-learning algorithms imple-\n",
    "menting such priors. This paper reviews recent work in the area of\n",
    "unsupervised feature learning and deep learning, covering advances\n",
    "in probabilistic models, auto-encoders, manifold learning, and deep\n",
    "networks. This motivates longer-term unanswered questions about the\n",
    "appropriate objectives for learning good representations, for computing\n",
    "representations (i.e., inference), and the geometrical connections be-\n",
    "tween representation learning, density estimation and manifold learning.\n",
    "Index Terms—Deep learning, representation learning, feature learning,\n",
    "unsupervised learning, Boltzmann Machine, autoencoder, neural nets\n",
    "1 INTRODUCTION\n",
    "The performance of machine learning methods is heavily\n",
    "dependent on the choice of data representation (or features)\n",
    "on which they are applied. For that reason, much of the actual\n",
    "effort in deploying machine learning algorithms goes into the\n",
    "design of preprocessing pipelines and data transformations that\n",
    "result in a representation of the data that can support effective\n",
    "machine learning. Such feature engineering is important but\n",
    "labor-intensive and highlights the weakness of current learning\n",
    "algorithms: their inability to extract and organize the discrimi-\n",
    "native information from the data. Feature engineering is a way\n",
    "to take advantage of human ingenuity and prior knowledge to\n",
    "compensate for that weakness. In order to expand the scope\n",
    "and ease of applicability of machine learning, it would be\n",
    "highly desirable to make learning algorithms less dependent\n",
    "on feature engineering, so that novel applications could be\n",
    "constructed faster, and more importantly, to make progress\n",
    "towards Artificial Intelligence (AI). An AI must fundamentally\n",
    "understand the world around us, and we argue that this can\n",
    "only be achieved if it can learn to identify and disentangle the\n",
    "underlying explanatory factors hidden in the observed milieu\n",
    "of low-level sensory data.\n",
    "This paper is about representation learning, i.e., learning\n",
    "representations of the data that make it easier to extract useful\n",
    "information when building classifiers or other predictors. In\n",
    "the case of probabilistic models, a good representation is often\n",
    "one that captures the posterior distribution of the underlying\n",
    "explanatory factors for the observed input. A good representa-\n",
    "tion is also one that is useful as input to a supervised predictor.\n",
    "Among the various ways of learning representations, this paper\n",
    "focuses on deep learning methods: those that are formed by\n",
    "the composition of multiple non-linear transformations, with\n",
    "the goal of yielding more abstract – and ultimately more useful\n",
    "– representations. Here we survey this rapidly developing area\n",
    "with special emphasis on recent progress. We consider some\n",
    "of the fundamental questions that have been driving research\n",
    "in this area. Specifically, what makes one representation better\n",
    "than another? Given an example, how should we compute its\n",
    "representation, i.e. perform feature extraction? Also, what are\n",
    "appropriate objectives for learning good representations?\n",
    "2 WHY SHOULD WE CARE ABOUT LEARNING\n",
    "REPRESENTATIONS?\n",
    "Representation learning has become a field in itself in the\n",
    "machine learning community, with regular workshops at the\n",
    "leading conferences such as NIPS and ICML, and a new\n",
    "conference dedicated to it, ICLR1, sometimes under the header\n",
    "of Deep Learning or Feature Learning. Although depth is an\n",
    "important part of the story, many other priors are interesting\n",
    "and can be conveniently captured when the problem is cast as\n",
    "one of learning a representation, as discussed in the next sec-\n",
    "tion. The rapid increase in scientific activity on representation\n",
    "learning has been accompanied and nourished by a remarkable\n",
    "string of empirical successes both in academia and in industry.\n",
    "Below, we briefly highlight some of these high points.\n",
    "Speech Recognition and Signal Processing\n",
    "Speech was one of the early applications of neural networks,\n",
    "in particular convolutional (or time-delay) neural networks 2.\n",
    "The recent revival of interest in neural networks, deep learning,\n",
    "and representation learning has had a strong impact in the\n",
    "area of speech recognition, with breakthrough results (Dahl\n",
    "et al., 2010; Deng et al., 2010; Seide et al., 2011a; Mohamed\n",
    "et al., 2012; Dahl et al., 2012; Hinton et al., 2012) obtained\n",
    "by several academics as well as researchers at industrial labs\n",
    "bringing these algorithms to a larger scale and into products.\n",
    "For example, Microsoft has released in 2012 a new version\n",
    "of their MAVIS (Microsoft Audio Video Indexing Service)\n",
    "1. International Conference on Learning Representations\n",
    "2. See Bengio (1993) for a review of early work in this area.\n",
    "arXiv:1206.5538v3 [cs.LG] 23 Apr 2014\n",
    "2\n",
    "speech system based on deep learning (Seide et al., 2011a).\n",
    "These authors managed to reduce the word error rate on\n",
    "four major benchmarks by about 30% (e.g. from 27.4% to\n",
    "18.5% on RT03S) compared to state-of-the-art models based\n",
    "on Gaussian mixtures for the acoustic modeling and trained on\n",
    "the same amount of data (309 hours of speech). The relative\n",
    "improvement in error rate obtained by Dahl et al. (2012) on a\n",
    "smaller large-vocabulary speech recognition benchmark (Bing\n",
    "mobile business search dataset, with 40 hours of speech) is\n",
    "between 16% and 23%.\n",
    "Representation-learning algorithms have also been applied\n",
    "to music, substantially beating the state-of-the-art in poly-\n",
    "phonic transcription (Boulanger-Lewandowski et al., 2012),\n",
    "with relative error improvement between 5% and 30% on a\n",
    "standard benchmark of 4 datasets. Deep learning also helped\n",
    "to win MIREX (Music Information Retrieval) competitions,\n",
    "e.g. in 2011 on audio tagging (Hamel et al., 2011).\n",
    "Object Recognition\n",
    "The beginnings of deep learning in 2006 have focused on\n",
    "the MNIST digit image classification problem (Hinton et al.,\n",
    "2006; Bengio et al., 2007), breaking the supremacy of SVMs\n",
    "(1.4% error) on this dataset3. The latest records are still held\n",
    "by deep networks: Ciresan et al. (2012) currently claims the\n",
    "title of state-of-the-art for the unconstrained version of the task\n",
    "(e.g., using a convolutional architecture), with 0.27% error,\n",
    "and Rifai et al. (2011c) is state-of-the-art for the knowledge-\n",
    "free version of MNIST, with 0.81% error.\n",
    "In the last few years, deep learning has moved from\n",
    "digits to object recognition in natural images, and the latest\n",
    "breakthrough has been achieved on the ImageNet dataset4\n",
    "bringing down the state-of-the-art error rate from 26.1% to\n",
    "15.3% (Krizhevsky et al., 2012).\n",
    "Natural Language Processing\n",
    "Besides speech recognition, there are many other Natural\n",
    "Language Processing (NLP) applications of representation\n",
    "learning. Distributed representations for symbolic data were\n",
    "introduced by Hinton (1986), and first developed in the\n",
    "context of statistical language modeling by Bengio et al.\n",
    "(2003) in so-called neural net language models (Bengio,\n",
    "2008). They are all based on learning a distributed repre-\n",
    "sentation for each word, called a word embedding. Adding a\n",
    "convolutional architecture, Collobert et al. (2011) developed\n",
    "the SENNA system5 that shares representations across the\n",
    "tasks of language modeling, part-of-speech tagging, chunking,\n",
    "named entity recognition, semantic role labeling and syntactic\n",
    "parsing. SENNA approaches or surpasses the state-of-the-art\n",
    "on these tasks but is simpler and much faster than traditional\n",
    "predictors. Learning word embeddings can be combined with\n",
    "learning image representations in a way that allow to associate\n",
    "text and images. This approach has been used successfully to\n",
    "build Google’s image search, exploiting huge quantities of data\n",
    "to map images and queries in the same space (Weston et al.,\n",
    "3. for the knowledge-free version of the task, where no image-specific prior\n",
    "is used, such as image deformations or convolutions\n",
    "4. The 1000-class ImageNet benchmark, whose results are detailed here:\n",
    "http://www.image-net.org/challenges/LSVRC/2012/results.html\n",
    "5. downloadable from http://ml.nec-labs.com/senna/\n",
    "2010) and it has recently been extended to deeper multi-modal\n",
    "representations (Srivastava and Salakhutdinov, 2012).\n",
    "The neural net language model was also improved by\n",
    "adding recurrence to the hidden layers (Mikolov et al., 2011),\n",
    "allowing it to beat the state-of-the-art (smoothed n-gram\n",
    "models) not only in terms of perplexity (exponential of the\n",
    "average negative log-likelihood of predicting the right next\n",
    "word, going down from 140 to 102) but also in terms of\n",
    "word error rate in speech recognition (since the language\n",
    "model is an important component of a speech recognition\n",
    "system), decreasing it from 17.2% (KN5 baseline) or 16.9%\n",
    "(discriminative language model) to 14.4% on the Wall Street\n",
    "Journal benchmark task. Similar models have been applied\n",
    "in statistical machine translation (Schwenk et al., 2012; Le\n",
    "et al., 2013), improving perplexity and BLEU scores. Re-\n",
    "cursive auto-encoders (which generalize recurrent networks)\n",
    "have also been used to beat the state-of-the-art in full sentence\n",
    "paraphrase detection (Socher et al., 2011a) almost doubling the\n",
    "F1 score for paraphrase detection. Representation learning can\n",
    "also be used to perform word sense disambiguation (Bordes\n",
    "et al., 2012), bringing up the accuracy from 67.8% to 70.2%\n",
    "on the subset of Senseval-3 where the system could be applied\n",
    "(with subject-verb-object sentences). Finally, it has also been\n",
    "successfully used to surpass the state-of-the-art in sentiment\n",
    "analysis (Glorot et al., 2011b; Socher et al., 2011b).\n",
    "Multi-Task and Transfer Learning, Domain Adaptation\n",
    "Transfer learning is the ability of a learning algorithm to\n",
    "exploit commonalities between different learning tasks in order\n",
    "to share statistical strength, and transfer knowledge across\n",
    "tasks. As discussed below, we hypothesize that representation\n",
    "learning algorithms have an advantage for such tasks because\n",
    "they learn representations that capture underlying factors, a\n",
    "subset of which may be relevant for each particular task, as\n",
    "illustrated in Figure 1. This hypothesis seems confirmed by a\n",
    "number of empirical results showing the strengths of repre-\n",
    "sentation learning algorithms in transfer learning scenarios.raw input x\n",
    "task 1\n",
    "output y 1\n",
    "task 3\n",
    "output y 3\n",
    "task 2\n",
    "output y 2\n",
    "Task%A% Task%B% Task%C%\n",
    "%output%\n",
    "%input%\n",
    "%shared%\n",
    "subsets%of%\n",
    "\n",
    "'''\n",
    "\n",
    "task = '''\n",
    "\n",
    "---\n",
    "\n",
    "Task:\n",
    "Summarize the authors, affiliations (company, university, other institution) and the keywords (if available or apparent from the abstract/ introduction) from the above text in the following format. Don't write code. I just need the output in this python-dictionary format so that I can use it in python in subsequent steps.\n",
    "\n",
    "Example output:\n",
    "{\n",
    "\"authors\": [\"Yan LeCun\", \"Jürgen Schmidthuber\"],\n",
    "\"affiliations\": [\"NewYork University\", \"King Abdullah University of Science and Technology\", \"The Swiss AI Lab\", \"IDSIA\"],\n",
    "\"keywords\": \"supervised learning\", \"classification\"\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "051589b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "\"authors\": [\"Yoshua Bengio\", \"Aaron Courville\", \"Pascal Vincent\"],\n",
      "\"affiliations\": [\"Department of computer science and operations research, U. Montreal\", \"Canadian Institute for Advanced Research (CIFAR)\"],\n",
      "\"keywords\": [\"Deep learning\", \"representation learning\", \"feature learning\", \"unsupervised learning\", \"Boltzmann Machine\", \"autoencoder\", \"neural nets\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Define the payload, specifying the \"Mistral Instruct 7B Q4\" model\n",
    "payload = json.dumps({\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "            \"role\": \"system\"\n",
    "        },\n",
    "        {\n",
    "            \"content\": context + task,\n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "    ],\n",
    "    \"model\": \"mistral-ins-7b-q4\",  # Specify the model here\n",
    "    \"stream\": False,\n",
    "    \"max_tokens\": 1000,\n",
    "    \"stop\": [],\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"presence_penalty\": 0,\n",
    "    \"temperature\": 0.1, # 0.7\n",
    "    \"top_p\": 0.99, # 0.95\n",
    "})\n",
    "\n",
    "\n",
    "# Make the POST request\n",
    "conn.request(\"POST\", \"/v1/chat/completions\", payload, headers)\n",
    "\n",
    "# Get the response\n",
    "res = conn.getresponse()\n",
    "data = res.read()\n",
    "\n",
    "response = json.loads(data.decode(\"utf-8\"))\n",
    "\n",
    "# Print the response\n",
    "# response\n",
    "# response.keys()\n",
    "# response[\"choices\"][0].keys()\n",
    "response_text = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164da15f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
